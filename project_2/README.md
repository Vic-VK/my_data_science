# Проект 2. Анализ вакансий из HeadHunter

## Оглавление
[1. Описание проекта](#Описание-проекта)  
[2. Какой кейс решаем?](#Какой-кейс-решаем)  
[3. Краткая информация о данных](#Краткая-информация-о-данных)  
[4. Этапы работы над проектом](#Этапы-работы-над-проектом)  
[5. Результат](#Результат)  
[6. Выводы](#Выводы)  

### Описание проекта
В данной части проекта по созданию модели машинного обучения(которая будет рекомендовать вакансии клиентам агентства, претендующим на позицию Data Scientist) проводим подготовительную работа, а именно, что из себя представляют данные и насколько они соответствуют целям проекта. В литературе эта часть работы над ML-проектом называется Data Understanding, или анализ данных.

:arrow_up:[к оглавлению](#Оглавление)

### Какой кейс решаем?
Необходимо провести анализ данных из базы вакансий, выгруженной с сайта поиска вакансий hh.ru.

**Условия соревнования**
- Каждая из частей будет состоять из блока практических заданий, которые вам необходимо выполнить в своих Jupyter-ноутбуках, и контрольных вопросов на платформе, которые проверяются автоматически.
- Ноутбук необходимо оформить на основе предоставленного шаблона и требований.
- Отправить свой код ментору для code-ревью.

**Метрика качества**
 Результаты оцениваются на основании выполнения требований к оформлению ноутбука:
 - Решение оформляется только в Jupyter Notebook.
 - Решение оформляется в соответствии с ноутбуком-шаблоном.
 - Каждое задание выполняется в отдельной ячейке, выделенной под задание (в шаблоне они помечены как ваш код здесь).
 - Код для каждого задания оформляется в одной-двух jupyter-ячейках (не стоит создавать множество ячеек для решения задачи, это усложняет проверку).
 - Текст SQL-запросов и код на Python должны быть читаемыми. Не забывайте про отступы в SQL-коде.
 - Пользуйтесь руководством PEP 8.
 - Выводы по каждому этапу оформляются в формате Markdown в отдельной ячейке (в шаблоне они помечены как ваши выводы здесь).
 - Выводы можно дополнительно проиллюстрировать с помощью графиков. Они оформляются в соответствии с теми правилами, которые мы приводили в модуле по визуализации данных.
 - Не забудьте удалить ячейку с данными соединения перед фиксацией работы в GitHub.

**Что практикуем**
+ проведение обработки, анализа данных и оформление отчетов с помощью средств python.

:arrow_up:[к оглавлению](#Оглавление)

### Краткая информация о данных
Исходные данные находятся в 5 таблицах в базе данных на сервере skillfactory по представленным пораметрам подключения. С помощью библиотеке psycopg2 и через заданные параметры подключаемся к базе данных вакансий, выгруженных с сайта компании HeadHunter.

:arrow_up:[к оглавлению](#Оглавление)

 ### Этапы работы над проектом
1. Знакомство с данными.

2. Предварительный анализ данных.

3. Детальный анализ вакансий.

4. Анализ работодателей.

5. Предметный анализ.

:arrow_up:[к оглавлению](#Оглавление)

 ### Результат
Для создания требуемой модели, которая будет рекомендовать вакансии клиентам агентства, претендующим на позицию Data Scientist, был проведен анализ данных и подготовлены необходимые данные.

:arrow_up:[к оглавлению](#Оглавление)

### Выводы
В результате работы подготовлен ноутбук в котором реализованы основные этапы анализа вакансий при помощи SQL запросов к базе данных. Ход работы и ее результаты оформлены в виде [Jupyther Notebook.](Project_2.ipynb)

:arrow_up:[к оглавлению](#Оглавление)